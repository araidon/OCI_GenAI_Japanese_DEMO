{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OCI Generative AI 日本語化 デモ\n",
    "\n",
    "OCI GenAIに日本語でぶん投げたプロンプトを、日本語で返す"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Install Packages\n",
    "%pip install oci python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ローカルの設定ファイルを読み込む\n",
    "%load_ext dotenv\n",
    "%dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import oci\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "compartment_id = os.environ.get(\"COMPARTMENT_ID\")\n",
    "config = oci.config.from_file('~/.oci/config', \"DEFAULT\")\n",
    "endpoint = os.environ.get(\"GENAI_ENDPOINT\")\n",
    "\n",
    "key=\"key\"\n",
    "language_en = \"en\"\n",
    "language_ja = \"ja\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set prompt\n",
    "prompt = \"Oracle Cloud Infrastractureの紹介についてのブログ記事を書きたい。小学生向けのわかりやすさで、目次を考えてください。\"\n",
    "\n",
    "# set parameters\n",
    "max_tokens = 600\n",
    "temperature = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### exec generative ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generative_ai_inference_client = oci.generative_ai_inference.GenerativeAiInferenceClient(config=config, service_endpoint=endpoint, retry_strategy=oci.retry.NoneRetryStrategy(), timeout=(10,240))\n",
    "generate_text_detail = oci.generative_ai_inference.models.GenerateTextDetails()\n",
    "llm_inference_request = oci.generative_ai_inference.models.CohereLlmInferenceRequest()\n",
    "llm_inference_request.prompt = prompt\n",
    "llm_inference_request.max_tokens = max_tokens\n",
    "llm_inference_request.temperature = temperature\n",
    "llm_inference_request.frequency_penalty = 0\n",
    "llm_inference_request.top_p = 0.75\n",
    "\n",
    "generate_text_detail.serving_mode = oci.generative_ai_inference.models.OnDemandServingMode(model_id=os.environ.get(\"MODEL_ID\"))\n",
    "generate_text_detail.inference_request = llm_inference_request\n",
    "generate_text_detail.compartment_id = compartment_id\n",
    "generate_text_response = generative_ai_inference_client.generate_text(generate_text_detail)\n",
    "\n",
    "# Print result\n",
    "# print(\n",
    "#     generate_text_response.data.inference_response.generated_texts[0].text\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### exec language translation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_language_client = oci.ai_language.AIServiceLanguageClient(config)\n",
    "\n",
    "#text=\"Hello, world!\"\n",
    "text=generate_text_response.data.inference_response.generated_texts[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send the request to service, some parameters are not required, see API\n",
    "# doc for more info\n",
    "batch_language_translation_response = ai_language_client.batch_language_translation(\n",
    "    batch_language_translation_details=oci.ai_language.models.BatchLanguageTranslationDetails(\n",
    "        documents=[\n",
    "            oci.ai_language.models.TextDocument(\n",
    "                key=key,\n",
    "                text=text,\n",
    "                language_code=language_en)],\n",
    "        compartment_id=compartment_id,\n",
    "        target_language_code=language_ja),\n",
    "    #opc_request_id=\"UUD9T8HFQPSFIX6KYQDU<unique_ID>\"\n",
    "    )\n",
    "\n",
    "# Get the data from response\n",
    "response_str = batch_language_translation_response.data.documents[0].translated_text\n",
    "\n",
    "# 行頭の不要な空白を削除、改行を追加\n",
    "response_str = response_str.lstrip()\n",
    "response_str = response_str.replace(\"。\", \"。\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the response\n",
    "print(response_str)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
